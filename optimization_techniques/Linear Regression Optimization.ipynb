{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de una regresión lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generación datos aleatoriamente a partir de un modelo de regresión lineal predefinido donde $-5 \\leq \\beta_{i} \\leq 5 \\quad i = 1, \\dots , K$ con al menos $K = 100$ variables explicativas y un mínimo de $n = 1000$ observaciones. Queremos ajustar un modelo de regresión lineal múltiple que explique la variable $Y$ en función de las demás $X (Y = \\beta^T X+\\epsilon)$, donde $\\beta = (\\beta_{0}, \\beta_{1}, \\beta_{2}, \\dots, \\beta_{k})^T$, usando \"*Least Squares Estimation*\":\n",
    "\n",
    "\\begin{align*}\n",
    "\\underset{\\beta}{\\min} & \\quad \\sum_{i=1}^{n} (y_{i}-\\beta^Tx_{i})^2\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "nsample = 1000\n",
    "nvariables=100\n",
    "X0 = np.ones([nsample,1]) # columna Beta_0, luego se concatena con las betas_i\n",
    "Xi = np.random.random([nsample,nvariables]) # Los valores de x_i están entre 0 y 1\n",
    "X = np.concatenate([X0, Xi],axis=1)\n",
    "beta = np.random.uniform(-5,5,size=([nvariables+1,1]))\n",
    "epsilon=np.random.normal(0,1,(nsample,1)) # El error se distribuye según una normal\n",
    "Y = np.dot(X,beta)+epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Estimación el valor de los parámetros de la regresión aplicando la solución analítica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed= 0.010654578036345183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.15233413],\n",
       "       [ 0.08546847],\n",
       "       [-1.17631577],\n",
       "       [-0.14108304],\n",
       "       [-1.40110843],\n",
       "       [ 1.45466706],\n",
       "       [ 3.44572396],\n",
       "       [ 2.91711795],\n",
       "       [-1.61313217],\n",
       "       [-0.1533509 ],\n",
       "       [-5.2159183 ],\n",
       "       [ 3.83021278],\n",
       "       [-2.49119516],\n",
       "       [-0.50809872],\n",
       "       [-3.48931602],\n",
       "       [ 1.93092301],\n",
       "       [ 0.36183479],\n",
       "       [-1.07269884],\n",
       "       [ 0.43490732],\n",
       "       [-3.30353155],\n",
       "       [ 3.02848066],\n",
       "       [-2.24520816],\n",
       "       [ 1.09712707],\n",
       "       [ 3.97565127],\n",
       "       [-4.55225206],\n",
       "       [-1.0815387 ],\n",
       "       [-3.62442509],\n",
       "       [ 3.86066222],\n",
       "       [-1.30016657],\n",
       "       [-2.93455736],\n",
       "       [ 1.8001133 ],\n",
       "       [ 0.38632804],\n",
       "       [ 3.26473816],\n",
       "       [ 2.59868212],\n",
       "       [ 4.79013726],\n",
       "       [-3.82204707],\n",
       "       [-4.20181943],\n",
       "       [ 4.29823584],\n",
       "       [ 4.69180638],\n",
       "       [-1.10880057],\n",
       "       [-0.1686732 ],\n",
       "       [-1.47431859],\n",
       "       [ 2.66300588],\n",
       "       [ 2.71941881],\n",
       "       [-2.64873996],\n",
       "       [-1.11712919],\n",
       "       [-2.65617814],\n",
       "       [-4.73107727],\n",
       "       [-4.39730118],\n",
       "       [-3.6545299 ],\n",
       "       [-4.53338759],\n",
       "       [-0.72897051],\n",
       "       [-4.38038223],\n",
       "       [ 3.55034356],\n",
       "       [ 2.25542917],\n",
       "       [ 2.80988338],\n",
       "       [ 1.26239187],\n",
       "       [ 1.6002725 ],\n",
       "       [-3.90060297],\n",
       "       [-4.38904367],\n",
       "       [ 4.69152963],\n",
       "       [-1.23971775],\n",
       "       [-4.3721753 ],\n",
       "       [-3.43485857],\n",
       "       [ 3.6417236 ],\n",
       "       [-2.7419417 ],\n",
       "       [-0.24696555],\n",
       "       [ 1.67912419],\n",
       "       [ 4.68899766],\n",
       "       [-4.83677255],\n",
       "       [-0.03785452],\n",
       "       [ 5.04009005],\n",
       "       [-3.54815054],\n",
       "       [-3.71347434],\n",
       "       [-4.10746108],\n",
       "       [ 0.10834192],\n",
       "       [-1.57435602],\n",
       "       [ 2.02058667],\n",
       "       [ 0.57063039],\n",
       "       [ 0.79287305],\n",
       "       [ 0.08262846],\n",
       "       [ 5.02195374],\n",
       "       [ 0.52049179],\n",
       "       [-4.19394057],\n",
       "       [-1.69558938],\n",
       "       [ 3.00532756],\n",
       "       [ 1.27468152],\n",
       "       [ 1.77589508],\n",
       "       [ 4.15013251],\n",
       "       [-0.48543632],\n",
       "       [-4.73943545],\n",
       "       [ 4.84575296],\n",
       "       [-0.26172513],\n",
       "       [-3.94308763],\n",
       "       [ 0.44529474],\n",
       "       [ 0.77501363],\n",
       "       [ 0.45677471],\n",
       "       [ 4.46968862],\n",
       "       [-1.83504262],\n",
       "       [-4.82630751],\n",
       "       [ 4.2150688 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.linalg import inv\n",
    "time_start = time.clock()\n",
    "beta_ls_exact = np.dot(np.dot(inv(np.dot(X.T,X)),X.T),Y)\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print('time elapsed=',time_elapsed)\n",
    "beta_ls_exact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Estimación el valor de los coeficientes de la regresión usando la herramienta minimize del paquete de Python scipy.optimize. Se prueban cuatro solvers diferentes y se comparan su eficiencia en términos de: número de iteraciones totales, número de evaluaciones de la función objetivo, gradiente y hesiano, así como el tiempo de computo total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fución de regresión que utilizamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_sq_reg(beta_ls, X, Y):\n",
    "    beta_ls = np.matrix(beta_ls)\n",
    "    z = Y-np.dot(X,beta_ls.T)\n",
    "    return np.dot(z.T,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función del *jacobiano*, derivada 1ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_sq_reg_jac(beta_ls,X,Y):\n",
    "    beta_ls = np.matrix(beta_ls)\n",
    "    pp = -2*np.dot((Y-np.dot(X,(beta_ls).T)).T,X)\n",
    "    aa = np.squeeze(np.asarray(pp)) # NO ENTIENDO np.squeeze, ni para que hace un cast de array (np.asarray)\n",
    "    return aa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función del *hessiano*, derivada 2ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_sq_reg_hess(beta_ls,X,Y):\n",
    "    ss = 2*np.dot(np.transpose(X),X) # NO ENTIENDO el resultado de la derivada 2ª. A mi me sale solo 2·X, no 2·X^2\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genramos un dataframe con los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparativo = pd.DataFrame(columns=['ejercicio','n_iter','n_eval','n_grad','n_hess','total_time_elapsed','iter_time_elapsed','error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión lineal con el Solver *SLSQP*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: OptimizeWarning: Unknown solver options: xtol\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 953.7738898681563\n",
      "            Iterations: 41\n",
      "            Function evaluations: 4310\n",
      "            Gradient evaluations: 41\n"
     ]
    }
   ],
   "source": [
    "beta_ls_ini = np.zeros(nvariables+1)\n",
    "time_start = time.clock()\n",
    "method = 'SLSQP'\n",
    "res = minimize(least_sq_reg, beta_ls_ini, args=(X, Y), method=method, options={'disp': True,'xtol': 1e-10})\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "error = np.linalg.norm(beta_ls_exact.T - res.x,ord=2)/np.linalg.norm(beta_ls_exact.T,ord=2)\n",
    "ejercicio = '1b'\n",
    "aux = [ejercicio,res.nit, res.nfev]\n",
    "try:\n",
    "    aux.append(res.njev)\n",
    "except Exception as e:\n",
    "    aux.append(None)\n",
    "try:\n",
    "    aux.append(res.nhev)\n",
    "except Exception as e:\n",
    "    aux.append(None)\n",
    "aux = aux + ['{:.8f}'.format(time_elapsed), '{:.8f}'.format(time_elapsed/res.nit),error]\n",
    "aux = pd.DataFrame(aux).T\n",
    "aux.columns = ['ejercicio','n_iter','n_eval','n_grad','n_hess','total_time_elapsed','iter_time_elapsed','error']\n",
    "aux.index = [method]\n",
    "df_comparativo = pd.concat([df_comparativo,aux])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión lineal con el Solver *CG*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 953.773888\n",
      "         Iterations: 67\n",
      "         Function evaluations: 149\n",
      "         Gradient evaluations: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: OptimizeWarning: Unknown solver options: xtol\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "beta_ls_ini = np.zeros(nvariables+1)\n",
    "time_start = time.clock()\n",
    "method = 'CG'\n",
    "res = minimize(least_sq_reg, beta_ls_ini, args=(X, Y), method=method, jac=least_sq_reg_jac, options={'disp': True,'xtol': 1e-10})\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "error = np.linalg.norm(beta_ls_exact.T - res.x,ord=2)/np.linalg.norm(beta_ls_exact.T,ord=2)\n",
    "ejercicio = '1b'\n",
    "aux = [ejercicio,res.nit, res.nfev]\n",
    "try:\n",
    "    aux.append(res.njev)\n",
    "except Exception as e:\n",
    "    aux.append(None)\n",
    "try:\n",
    "    aux.append(res.nhev)\n",
    "except Exception as e:\n",
    "    aux.append(None)\n",
    "aux = aux + ['{:.8f}'.format(time_elapsed), '{:.8f}'.format(time_elapsed/res.nit),error]\n",
    "aux = pd.DataFrame(aux).T\n",
    "aux.columns = ['ejercicio','n_iter','n_eval','n_grad','n_hess','total_time_elapsed','iter_time_elapsed','error']\n",
    "aux.index = [method]\n",
    "df_comparativo = pd.concat([df_comparativo,aux])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión lineal con el Solver *Quasi-Newton (BFGS)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 953.773888\n",
      "         Iterations: 133\n",
      "         Function evaluations: 191\n",
      "         Gradient evaluations: 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: OptimizeWarning: Unknown solver options: xtol\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "beta_ls_ini = np.zeros(nvariables+1)\n",
    "time_start = time.clock()\n",
    "method = 'BFGS'\n",
    "res = minimize(least_sq_reg, beta_ls_ini, args=(X, Y), method=method, jac=least_sq_reg_jac, options={'disp': True,'xtol': 1e-10})\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "error = np.linalg.norm(beta_ls_exact.T - res.x,ord=2)/np.linalg.norm(beta_ls_exact.T,ord=2)\n",
    "ejercicio = '1b'\n",
    "aux = [ejercicio,res.nit, res.nfev]\n",
    "try:\n",
    "    aux.append(res.njev)\n",
    "except Exception as e:\n",
    "    aux.append(None)\n",
    "try:\n",
    "    aux.append(res.nhev)\n",
    "except Exception as e:\n",
    "    aux.append(None)\n",
    "aux = aux + ['{:.8f}'.format(time_elapsed), '{:.8f}'.format(time_elapsed/res.nit),error]\n",
    "aux = pd.DataFrame(aux).T\n",
    "aux.columns = ['ejercicio','n_iter','n_eval','n_grad','n_hess','total_time_elapsed','iter_time_elapsed','error']\n",
    "aux.index = ['Quasi-Newton (BFGS)']\n",
    "df_comparativo = pd.concat([df_comparativo,aux])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión lineal con el Solver *Trust-exact*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 953.773888\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "         Hessian evaluations: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:627: OptimizeWarning: Unknown solver options: xtol\n",
      "  callback=callback, **options)\n"
     ]
    }
   ],
   "source": [
    "beta_ls_ini = np.zeros(nvariables+1)\n",
    "time_start = time.clock()\n",
    "method = 'trust-exact'\n",
    "res = minimize(least_sq_reg, beta_ls_ini, args=(X, Y), method= method, jac=least_sq_reg_jac, hess=least_sq_reg_hess, options={'disp': True,'xtol': 1e-10})\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "error = np.linalg.norm(beta_ls_exact.T - res.x,ord=2)/np.linalg.norm(beta_ls_exact.T,ord=2)\n",
    "ejercicio = '1b'\n",
    "aux = [ejercicio,res.nit, res.nfev]\n",
    "try:\n",
    "    aux.append(res.njev)\n",
    "except Exception as e:\n",
    "    aux.append(None)\n",
    "try:\n",
    "    aux.append(res.nhev)\n",
    "except Exception as e:\n",
    "    aux.append(None)\n",
    "aux = aux + ['{:.8f}'.format(time_elapsed), '{:.8f}'.format(time_elapsed/res.nit),error]\n",
    "aux = pd.DataFrame(aux).T\n",
    "aux.columns = ['ejercicio','n_iter','n_eval','n_grad','n_hess','total_time_elapsed','iter_time_elapsed','error']\n",
    "aux.index = [method]\n",
    "df_comparativo = pd.concat([df_comparativo,aux])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión lineal con el Solver *Newton-CG*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 953.773888\n",
      "         Iterations: 17\n",
      "         Function evaluations: 57\n",
      "         Gradient evaluations: 69\n",
      "         Hessian evaluations: 17\n"
     ]
    }
   ],
   "source": [
    "beta_ls_ini = np.zeros(nvariables+1)\n",
    "time_start = time.clock()\n",
    "method = 'Newton-CG'\n",
    "res = minimize(least_sq_reg, beta_ls_ini, args=(X, Y), method=method, jac=least_sq_reg_jac, hess=least_sq_reg_hess, options={'disp': True,'xtol': 1e-10})\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "error = np.linalg.norm(beta_ls_exact.T - res.x,ord=2)/np.linalg.norm(beta_ls_exact.T,ord=2)\n",
    "ejercicio = '1b'\n",
    "aux = [ejercicio,res.nit, res.nfev]\n",
    "try:\n",
    "    aux.append(res.njev)\n",
    "except Exception as e:\n",
    "    aux.append(None)\n",
    "try:\n",
    "    aux.append(res.nhev)\n",
    "except Exception as e:\n",
    "    aux.append(None)\n",
    "aux = aux + ['{:.8f}'.format(time_elapsed), '{:.8f}'.format(time_elapsed/res.nit),error]\n",
    "aux = pd.DataFrame(aux).T\n",
    "aux.columns = ['ejercicio','n_iter','n_eval','n_grad','n_hess','total_time_elapsed','iter_time_elapsed','error']\n",
    "aux.index = [method]\n",
    "df_comparativo = pd.concat([df_comparativo,aux])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ejercicio</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>n_eval</th>\n",
       "      <th>n_grad</th>\n",
       "      <th>n_hess</th>\n",
       "      <th>total_time_elapsed</th>\n",
       "      <th>iter_time_elapsed</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SLSQP</th>\n",
       "      <td>1b</td>\n",
       "      <td>41</td>\n",
       "      <td>4310</td>\n",
       "      <td>41</td>\n",
       "      <td>None</td>\n",
       "      <td>0.30910774</td>\n",
       "      <td>0.00753921</td>\n",
       "      <td>5.50764e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG</th>\n",
       "      <td>1b</td>\n",
       "      <td>67</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>None</td>\n",
       "      <td>0.04317675</td>\n",
       "      <td>0.00064443</td>\n",
       "      <td>7.33548e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quasi-Newton (BFGS)</th>\n",
       "      <td>1b</td>\n",
       "      <td>133</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>None</td>\n",
       "      <td>0.09339162</td>\n",
       "      <td>0.00070219</td>\n",
       "      <td>3.05078e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trust-exact</th>\n",
       "      <td>1b</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.03685605</td>\n",
       "      <td>0.00737121</td>\n",
       "      <td>2.50072e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Newton-CG</th>\n",
       "      <td>1b</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "      <td>69</td>\n",
       "      <td>17</td>\n",
       "      <td>0.03074226</td>\n",
       "      <td>0.00180837</td>\n",
       "      <td>8.71154e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ejercicio n_iter n_eval n_grad n_hess total_time_elapsed  \\\n",
       "SLSQP                      1b     41   4310     41   None         0.30910774   \n",
       "CG                         1b     67    149    149   None         0.04317675   \n",
       "Quasi-Newton (BFGS)        1b    133    191    191   None         0.09339162   \n",
       "trust-exact                1b      5      6      6      6         0.03685605   \n",
       "Newton-CG                  1b     17     57     69     17         0.03074226   \n",
       "\n",
       "                    iter_time_elapsed        error  \n",
       "SLSQP                      0.00753921  5.50764e-06  \n",
       "CG                         0.00064443  7.33548e-09  \n",
       "Quasi-Newton (BFGS)        0.00070219  3.05078e-14  \n",
       "trust-exact                0.00737121  2.50072e-14  \n",
       "Newton-CG                  0.00180837  8.71154e-12  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discusión resultados  \n",
    "<li> **Número de iteraciones**:  \n",
    "    Los métodos que tienen ayuda en la selección de la dirección (hessiano) iteran mucho menos, del orden un 10%-50%, precisamente por esa ayuda en la selección de la dirección.</li>\n",
    "<li> **Número de evaluaciones de la Función y graidente**:  \n",
    "    Al igual que en las iteraciones, los métodos que tienen ayuda en la selección de la dirección (hessiano) evaluan mucho menos la función y el gradiente.</li>\n",
    "<li> **Tiempo de computación**:  \n",
    "    Los métodos que tienen ayuda en la selección de la dirección (hessiano) tardan menos en computar. Esto es debido al menor número de iteraciones y no tanto al esfuerzo computacional ya que cada iteración tarda más, x10.</li>\n",
    "<li> **Error**:   \n",
    "    Al igual que antes, los métodos que tienen ayuda en la selección de la dirección (hessiano) tienen menos error ya que cerca de la solución se pueden acercar más ella por dicha ayuda.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Estimación del valor de los coeficientes de la regresión implementando:\n",
    "<li> i. Método del Gradiente.</li>\n",
    "<li> ii. Método de Newton.</li>\n",
    "<li> iii. Método de Quasi-Newton.</li>\n",
    "<li> iv. Método del Gradiente Estocástico.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. (0.5 punto) Método del Gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método solo utiliza la condición de que la derivada primera sobre beta sea menor que cero.  \n",
    "Produce un número alto de iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta:  [-0.31697509 -0.00662153 -1.12842702 -0.13851037 -1.45076361  1.37383216\n",
      "  3.40309994  2.94511846 -1.67679779 -0.33605802 -5.14917015  3.57361842\n",
      " -2.35532995 -0.34018469 -3.39500485  1.91605871  0.37329151 -1.03390348\n",
      "  0.32135236 -3.31478051  3.07825667 -2.26069776  1.03719729  3.85672777\n",
      " -4.39511457 -0.95608087 -3.62786652  3.85113841 -1.22576828 -2.69745281\n",
      "  1.68515777  0.3358071   3.24001294  2.56048493  4.6351544  -3.56378585\n",
      " -4.1704756   4.22150619  4.5477107  -1.12335419 -0.13198606 -1.38565998\n",
      "  2.5188029   2.6887277  -2.54306698 -0.87315576 -2.71195244 -4.7478493\n",
      " -4.34731996 -3.53495752 -4.51089892 -0.80290652 -4.20756185  3.50862689\n",
      "  2.05549256  2.69780797  1.22755207  1.5352091  -3.95129921 -4.21900455\n",
      "  4.52281705 -1.1518718  -4.20916379 -3.38414138  3.6791647  -2.68028956\n",
      " -0.28857676  1.64044801  4.62454051 -4.59274963 -0.15933797  4.97730581\n",
      " -3.39446043 -3.59152118 -3.88667801  0.11700816 -1.69522458  1.85461978\n",
      "  0.51507053  0.80711484  0.17746465  4.99012032  0.59005846 -4.10828476\n",
      " -1.64098283  3.09743431  1.17405979  1.72988677  4.03443494 -0.5021527\n",
      " -4.67278621  4.71094082 -0.24597031 -3.99999814  0.48278276  0.71092046\n",
      "  0.45113583  4.30764578 -1.69754638 -4.74390545  4.2829411 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:54: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definimos índices\n",
    "(n,m) = X.shape\n",
    "beta_ls = np.zeros(m) \n",
    "n_iter=1000\n",
    "\n",
    "# Definimos variables que usaremos para almacenar valores la Función Objetivo, alfa e iteraciones:\n",
    "OF_iter = np.zeros(n_iter)\n",
    "tol_iter = np.zeros(n_iter)\n",
    "alpha_iter = np.zeros(n_iter)\n",
    "\n",
    "# Inicializamos\n",
    "i = 0;\n",
    "tol = 1e4;\n",
    "epsilon = 1e-3;\n",
    "time_start = time.clock()\n",
    "cont_grad = 0\n",
    "cont_alpha = 0\n",
    "\n",
    "while (i <= n_iter-1) and (tol>epsilon):\n",
    "    # Dirección\n",
    "    cont_grad += 1\n",
    "    grad = least_sq_reg_jac(beta_ls,X,Y)\n",
    "    ddirect = -grad\n",
    "    \n",
    "    # Paso. Calculamos el paso más apropiado con la regla de Armijo.\n",
    "    alpha=0.05\n",
    "    sigma = 0.05\n",
    "    beta= 0.05\n",
    "    while (least_sq_reg(beta_ls+alpha*ddirect,X,Y) > least_sq_reg(beta_ls,X,Y)+alpha*sigma*np.dot(grad,ddirect)):\n",
    "        alpha=alpha*beta\n",
    "        cont_alpha += 1\n",
    "    \n",
    "    # Movimiento\n",
    "    beta_ls = beta_ls + alpha*ddirect\n",
    "    OF_iter[i] =least_sq_reg(beta_ls, X, Y)\n",
    "    tol = np.linalg.norm(least_sq_reg_jac(beta_ls,X,Y), ord=2)\n",
    "    tol_iter[i] = tol\n",
    "    alpha_iter[i]=alpha\n",
    "\n",
    "    # Aumentamos el contador\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start) \n",
    "error = np.linalg.norm(beta_ls_exact.T - beta_ls,ord=2)/np.linalg.norm(beta_ls_exact.T,ord=2)\n",
    "print('beta: ',beta_ls)\n",
    "\n",
    "ejercicio = '1c'\n",
    "method = 'Gradient'\n",
    "aux = [ejercicio,i, cont_grad, cont_alpha, '{:.8f}'.format(time_elapsed), '{:.8f}'.format(time_elapsed/i), error]\n",
    "aux = pd.DataFrame(aux).T\n",
    "aux.columns = ['ejercicio','n_iter','n_grad','n_alpha','total_time_elapsed','iter_time_elapsed','error']\n",
    "aux.index = [method]\n",
    "df_comparativo = pd.concat([df_comparativo,aux])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. (0.5 punto) Método de Newton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además del Jacobiano (derivada de orden 1) introducimos el hessiano (derivada de orden 2) para iterar menos veces ya que la elección de la dirección es más orientada.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta:  [-0.15233413  0.08546847 -1.17631575 -0.14108304 -1.40110842  1.45466705\n",
      "  3.44572392  2.91711792 -1.61313215 -0.1533509  -5.21591824  3.83021274\n",
      " -2.49119514 -0.50809872 -3.48931598  1.93092299  0.36183478 -1.07269883\n",
      "  0.43490732 -3.30353151  3.02848063 -2.24520813  1.09712706  3.97565123\n",
      " -4.55225201 -1.08153869 -3.62442505  3.86066218 -1.30016656 -2.93455732\n",
      "  1.80011328  0.38632804  3.26473812  2.59868209  4.79013721 -3.82204703\n",
      " -4.20181938  4.29823579  4.69180632 -1.10880056 -0.1686732  -1.47431858\n",
      "  2.66300585  2.71941878 -2.64873993 -1.11712918 -2.65617811 -4.73107722\n",
      " -4.39730113 -3.65452986 -4.53338754 -0.7289705  -4.38038218  3.55034352\n",
      "  2.25542915  2.80988335  1.26239186  1.60027249 -3.90060293 -4.38904362\n",
      "  4.69152958 -1.23971773 -4.37217525 -3.43485853  3.64172356 -2.74194167\n",
      " -0.24696555  1.67912417  4.68899761 -4.8367725  -0.03785452  5.04008999\n",
      " -3.5481505  -3.7134743  -4.10746104  0.10834192 -1.574356    2.02058665\n",
      "  0.57063039  0.79287304  0.08262846  5.02195368  0.52049178 -4.19394052\n",
      " -1.69558936  3.00532753  1.27468151  1.77589506  4.15013246 -0.48543631\n",
      " -4.7394354   4.84575291 -0.26172513 -3.94308759  0.44529474  0.77501362\n",
      "  0.4567747   4.46968857 -1.8350426  -4.82630746  4.21506876]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:57: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definimos índices\n",
    "(n,m) = X.shape\n",
    "beta_ls = np.zeros(m) \n",
    "n_iter=1000\n",
    "\n",
    "# Definimos variables que usaremos para almacenar valores la Función Objetivo, alfa e iteraciones:\n",
    "OF_iter = np.zeros(n_iter)\n",
    "tol_iter = np.zeros(n_iter)\n",
    "alpha_iter = np.zeros(n_iter)\n",
    "\n",
    "# Inicializamos\n",
    "i = 0;\n",
    "tol = 1e4;\n",
    "epsilon = 1e-3;\n",
    "time_start = time.clock()\n",
    "cont_grad = 0\n",
    "cont_hess = 0\n",
    "cont_alpha = 0\n",
    "\n",
    "while (i <= n_iter-1) and (tol>epsilon):\n",
    "    # Dirección\n",
    "    cont_grad += 1\n",
    "    cont_hess += 1\n",
    "    grad = least_sq_reg_jac(beta_ls,X,Y)\n",
    "    hess = least_sq_reg_hess(beta_ls,X,Y)\n",
    "    ddirect = -np.dot(np.linalg.inv(hess),grad)\n",
    "    \n",
    "    # Paso. Calculamos el paso más apropiado con la regla de Armijo.\n",
    "    alpha=0.05\n",
    "    sigma = 0.05\n",
    "    beta= 0.05\n",
    "    while (least_sq_reg(beta_ls+alpha*ddirect,X,Y) > least_sq_reg(beta_ls,X,Y)+alpha*sigma*np.dot(grad,ddirect)):\n",
    "        alpha=alpha*beta\n",
    "        cont_alpha += 1\n",
    "    \n",
    "    # Movimiento\n",
    "    beta_ls = beta_ls + alpha*ddirect\n",
    "    OF_iter[i] =least_sq_reg(beta_ls, X, Y)\n",
    "    tol = np.linalg.norm(least_sq_reg_jac(beta_ls,X,Y), ord=2)\n",
    "    tol_iter[i] = tol\n",
    "    alpha_iter[i] = alpha\n",
    "\n",
    "    # Aumentamos el contador\n",
    "    i += 1\n",
    "\n",
    "\n",
    "time_elapsed = (time.clock() - time_start) \n",
    "error = np.linalg.norm(beta_ls_exact.T - beta_ls,ord=2)/np.linalg.norm(beta_ls_exact.T,ord=2)\n",
    "print('beta: ',beta_ls)\n",
    "\n",
    "ejercicio = '1c'\n",
    "method = 'Newton'\n",
    "aux = [ejercicio,i, cont_grad, cont_alpha, '{:.8f}'.format(time_elapsed), '{:.8f}'.format(time_elapsed/i), error]\n",
    "aux = pd.DataFrame(aux).T\n",
    "aux.columns = ['ejercicio','n_iter','n_grad','n_alpha','total_time_elapsed','iter_time_elapsed','error']\n",
    "aux.index = [method]\n",
    "df_comparativo = pd.concat([df_comparativo,aux])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. (0.5 punto) Método de Quasi-Newton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método Quasi-Newton no utiliza el hessiano lo que agiliza su computación penalizando algo su precisión.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta:  [-0.15233413  0.08546847 -1.17631577 -0.14108304 -1.40110843  1.45466706\n",
      "  3.44572396  2.91711795 -1.61313217 -0.1533509  -5.2159183   3.83021278\n",
      " -2.49119516 -0.50809872 -3.48931602  1.93092301  0.36183479 -1.07269884\n",
      "  0.43490732 -3.30353155  3.02848066 -2.24520816  1.09712707  3.97565127\n",
      " -4.55225206 -1.0815387  -3.62442509  3.86066222 -1.30016657 -2.93455736\n",
      "  1.8001133   0.38632804  3.26473816  2.59868212  4.79013726 -3.82204707\n",
      " -4.20181943  4.29823584  4.69180638 -1.10880057 -0.1686732  -1.47431859\n",
      "  2.66300588  2.71941881 -2.64873996 -1.11712919 -2.65617814 -4.73107727\n",
      " -4.39730118 -3.6545299  -4.53338759 -0.72897051 -4.38038223  3.55034356\n",
      "  2.25542917  2.80988338  1.26239187  1.6002725  -3.90060297 -4.38904367\n",
      "  4.69152963 -1.23971775 -4.3721753  -3.43485857  3.6417236  -2.7419417\n",
      " -0.24696555  1.67912419  4.68899766 -4.83677255 -0.03785452  5.04009005\n",
      " -3.54815054 -3.71347434 -4.10746108  0.10834192 -1.57435602  2.02058667\n",
      "  0.57063039  0.79287305  0.08262846  5.02195374  0.52049179 -4.19394057\n",
      " -1.69558938  3.00532756  1.27468152  1.77589508  4.15013251 -0.48543632\n",
      " -4.73943545  4.84575296 -0.26172513 -3.94308763  0.44529474  0.77501363\n",
      "  0.45677471  4.46968862 -1.83504262 -4.82630751  4.2150688 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:58: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definimos índices\n",
    "(n,m) = X.shape\n",
    "\n",
    "beta_ls = np.zeros(m) \n",
    "n_iter = 1000\n",
    "\n",
    "# Definimos variables que usaremos para almacenar valores la Función Objetivo, alfa e iteraciones:\n",
    "OF_iter = np.zeros(n_iter)\n",
    "tol_iter = np.zeros(n_iter)\n",
    "\n",
    "# Inicializamos\n",
    "i = 0;\n",
    "tol = 1e3;\n",
    "epsilon = 1e-3;\n",
    "alpha = 1\n",
    "hess = least_sq_reg_hess(beta_ls,X,Y)\n",
    "time_start = time.clock()\n",
    "cont_grad = 0\n",
    "\n",
    "while (i <= n_iter-1) and (tol>epsilon):\n",
    "    # Dirección\n",
    "    cont_grad += 1\n",
    "    grad = least_sq_reg_jac(beta_ls,X,Y)\n",
    "    B = hess\n",
    "    ddirect = -np.dot(np.linalg.inv(B),grad)\n",
    "    \n",
    "    # Paso. Calculamos el paso más apropiado con la regla de Armijo.\n",
    "    sigma = 0.05\n",
    "    beta= 0.05\n",
    "    while (least_sq_reg(beta_ls+alpha*ddirect,X,Y) > least_sq_reg(beta_ls,X,Y)+alpha*sigma*np.dot(grad,ddirect)):\n",
    "        alpha=alpha*beta\n",
    "        cont_alpha += 1\n",
    "    \n",
    "    # Movimiento\n",
    "    beta_ls0 = beta_ls\n",
    "    beta_ls = beta_ls + alpha*ddirect  \n",
    "    OF_iter[i] =least_sq_reg(beta_ls, X, Y)\n",
    "    s = beta_ls - beta_ls0\n",
    "    y = least_sq_reg_jac(beta_ls,X,Y) - grad\n",
    "    hess = B + (y-B*s)*(y-B*s).T/(y-B*s).T*s\n",
    "    tol=np.linalg.norm(least_sq_reg_jac(beta_ls,X,Y), ord=2)\n",
    "    tol_iter[i]=tol\n",
    "\n",
    "    # Aumentamos el contador\n",
    "    i += 1\n",
    "\n",
    "\n",
    "time_elapsed = (time.clock() - time_start) \n",
    "error = np.linalg.norm(beta_ls_exact.T - beta_ls,ord=2)/np.linalg.norm(beta_ls_exact.T,ord=2)\n",
    "print('beta: ',beta_ls)\n",
    "\n",
    "ejercicio = '1c'\n",
    "method = 'Quasi-Newton'\n",
    "aux = [ejercicio,i, cont_grad, cont_alpha, '{:.8f}'.format(time_elapsed), '{:.8f}'.format(time_elapsed/i), error]\n",
    "aux = pd.DataFrame(aux).T\n",
    "aux.columns = ['ejercicio','n_iter','n_grad','n_alpha','total_time_elapsed','iter_time_elapsed','error']\n",
    "aux.index = [method]\n",
    "df_comparativo = pd.concat([df_comparativo,aux])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ejercicio</th>\n",
       "      <th>error</th>\n",
       "      <th>iter_time_elapsed</th>\n",
       "      <th>n_alpha</th>\n",
       "      <th>n_eval</th>\n",
       "      <th>n_grad</th>\n",
       "      <th>n_hess</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>total_time_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SLSQP</th>\n",
       "      <td>1b</td>\n",
       "      <td>5.50764e-06</td>\n",
       "      <td>0.00753921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4310</td>\n",
       "      <td>41</td>\n",
       "      <td>None</td>\n",
       "      <td>41</td>\n",
       "      <td>0.30910774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG</th>\n",
       "      <td>1b</td>\n",
       "      <td>7.33548e-09</td>\n",
       "      <td>0.00064443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>None</td>\n",
       "      <td>67</td>\n",
       "      <td>0.04317675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quasi-Newton (BFGS)</th>\n",
       "      <td>1b</td>\n",
       "      <td>3.05078e-14</td>\n",
       "      <td>0.00070219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>None</td>\n",
       "      <td>133</td>\n",
       "      <td>0.09339162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trust-exact</th>\n",
       "      <td>1b</td>\n",
       "      <td>2.50072e-14</td>\n",
       "      <td>0.00737121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.03685605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Newton-CG</th>\n",
       "      <td>1b</td>\n",
       "      <td>8.71154e-12</td>\n",
       "      <td>0.00180837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>69</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.03074226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient</th>\n",
       "      <td>1c</td>\n",
       "      <td>0.0358966</td>\n",
       "      <td>0.00049580</td>\n",
       "      <td>2816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.49580111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Newton</th>\n",
       "      <td>1c</td>\n",
       "      <td>1.11513e-08</td>\n",
       "      <td>0.00104918</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357</td>\n",
       "      <td>0.37455648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quasi-Newton</th>\n",
       "      <td>1c</td>\n",
       "      <td>1.66258e-14</td>\n",
       "      <td>0.00217222</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00217222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ejercicio        error iter_time_elapsed n_alpha n_eval  \\\n",
       "SLSQP                      1b  5.50764e-06        0.00753921     NaN   4310   \n",
       "CG                         1b  7.33548e-09        0.00064443     NaN    149   \n",
       "Quasi-Newton (BFGS)        1b  3.05078e-14        0.00070219     NaN    191   \n",
       "trust-exact                1b  2.50072e-14        0.00737121     NaN      6   \n",
       "Newton-CG                  1b  8.71154e-12        0.00180837     NaN     57   \n",
       "Gradient                   1c    0.0358966        0.00049580    2816    NaN   \n",
       "Newton                     1c  1.11513e-08        0.00104918       0    NaN   \n",
       "Quasi-Newton               1c  1.66258e-14        0.00217222       0    NaN   \n",
       "\n",
       "                    n_grad n_hess n_iter total_time_elapsed  \n",
       "SLSQP                   41   None     41         0.30910774  \n",
       "CG                     149   None     67         0.04317675  \n",
       "Quasi-Newton (BFGS)    191   None    133         0.09339162  \n",
       "trust-exact              6      6      5         0.03685605  \n",
       "Newton-CG               69     17     17         0.03074226  \n",
       "Gradient              1000    NaN   1000         0.49580111  \n",
       "Newton                 357    NaN    357         0.37455648  \n",
       "Quasi-Newton             1    NaN      1         0.00217222  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discusión  \n",
    "<li> **Número de iteraciones**:  \n",
    "    Los métodos que tienen ayuda en la selección de la dirección (hessiano) iteran muchísimo menos, del orden de menos de un 30%, precisamente por esa ayuda en la selección de la dirección.  \n",
    "Con respecto a resultado del ejercico 1b, no sé porqué Newton tiene más iteraciones en este caso ya que le damos una ayuda extra con Armijo rule.</li>\n",
    "<li> **Número de evaluaciones de la Función y gradiente**:  \n",
    "    Al igual que en las iteraciones, los métodos que tienen ayuda en la selección de la dirección (hessiano) evaluan mucho menos la función y el gradiente.</li>\n",
    "<li> **Tiempo de computación**:  \n",
    "    Los métodos que tienen ayuda en la selección de la dirección (hessiano) tardan menos en computar. Esto es debido al menor número de iteraciones y no tanto al esfuerzo computacional ya que cada iteración tarda más, x10.</li>\n",
    "<li> **Error**:   \n",
    "    Al igual que antes, los métodos que tienen ayuda en la selección de la dirección (hessiano) tienen menos error ya que cerca de la solución se pueden acercar más ella por dicha ayuda.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) La técnica *Least Absolute Regression* busca aquellos $\\beta = (\\beta_{0}, \\beta_{1}, \\beta_{2}, \\dots, \\beta_{k})^T$ que minimizen la suma de los valores absolutos de los residuos:\n",
    "\n",
    "\\begin{align*}\n",
    "\\underset{\\beta}{\\min} & \\quad \\sum_{i=1}^{n} |y_{i}-\\beta^Tx_{i}|\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Se plantea una linealización de esta formulación, implementala en Pyomo, y se compara la solución con la obtenida en a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solución\n",
    "Variables de decisión:\n",
    "<li>$\\beta_{j} \\equiv$ Variables</li>\n",
    "<li>$z \\equiv$ Variable auxiliar</li>\n",
    "\n",
    "\n",
    "Función Objetivo:\n",
    "\n",
    "\\begin{align*}\n",
    "\\underset{\\beta_{j}}{\\min} & \\quad \\sum_{i=1}^{n} |Y_{i}-X_{i,j}\\beta_{j}|_{1}\n",
    "\\end{align*}\n",
    "  \n",
    "Linealización de la Función Objetivo:\n",
    "\n",
    "\\begin{align*}\n",
    "\\underset{\\beta,z}{\\min} & \\quad \\sum_{i=1}^{n} z_{i}\n",
    "\\end{align*} \n",
    "  \n",
    "Restricciones:\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{s.t.:} \\quad  &\\\\\n",
    "\\text{(1)} \\quad   &-z_{i} \\leq \\sum_{1}^{n}Y_{i}-X_{i,j}\\beta_{j} \\leq z_{i}\\\\\n",
    "\\text{(2)} \\quad   &z_{i} \\geq 0\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "nsample = 1000\n",
    "nvariable = 100\n",
    "X0 = np.ones([nsample,1]) # columna Beta_0, luego se concatena con las betas_i\n",
    "Xi = np.random.random([nsample,nvariable]) # Los valores de x_i están entre 0 y 1\n",
    "X_real = np.concatenate([X0, Xi],axis=1)\n",
    "beta_exact = np.random.uniform(-5,5,size=([nvariable+1,1]))\n",
    "epsilon = np.random.normal(0,1,(nsample,1)) # El error se distribuye según una normal\n",
    "Y_real = np.dot(X_real,beta_exact) + epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.09052581,  0.19869926, -1.11767149, -0.18293121, -1.35252005,\n",
       "         1.61902421,  3.33924241,  2.89270415, -1.58115317, -0.00832208,\n",
       "        -5.16653547,  3.80695085, -2.52756072, -0.60230156, -3.41574713,\n",
       "         1.94199616,  0.31691582, -1.10140209,  0.34724384, -3.2295255 ,\n",
       "         3.0541115 , -2.28002653,  1.09166082,  3.89092617, -4.55164708,\n",
       "        -0.98121112, -3.74559067,  3.81785943, -1.43353035, -3.00302431,\n",
       "         1.91587336,  0.47522447,  3.20621142,  2.53756488,  4.76148229,\n",
       "        -3.77023926, -4.29137061,  4.08332937,  4.75149469, -1.07402046,\n",
       "        -0.1627864 , -1.50364058,  2.75673853,  2.71275847, -2.61001203,\n",
       "        -1.13673819, -2.64519134, -4.69200552, -4.27041648, -3.60160089,\n",
       "        -4.46619508, -0.76311173, -4.53933745,  3.61849958,  2.36972625,\n",
       "         2.75719592,  1.34452077,  1.7098212 , -3.87090893, -4.3579809 ,\n",
       "         4.6713998 , -1.36776325, -4.36418815, -3.38316912,  3.55917414,\n",
       "        -2.92798701, -0.26201774,  1.64232862,  4.87189662, -4.9456575 ,\n",
       "        -0.04861403,  5.0799923 , -3.5886296 , -3.90931239, -4.09108574,\n",
       "        -0.00865064, -1.58503077,  2.09486941,  0.48627556,  1.01288405,\n",
       "         0.04799078,  4.96972438,  0.4249463 , -4.18098417, -1.71881043,\n",
       "         2.89274549,  1.35233011,  1.94791261,  4.20127544, -0.56425883,\n",
       "        -4.59462881,  4.80084453, -0.38580071, -3.9269474 ,  0.28534764,\n",
       "         0.87578027,  0.45381054,  4.39550697, -1.9063284 , -4.96985611,\n",
       "         4.25597609])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyomo.environ import *\n",
    "opt = SolverFactory(\"glpk\")\n",
    "from pyomo.opt import SolverFactory\n",
    "\n",
    "n = 1000;\n",
    "m = 101;\n",
    "\n",
    "def LeastAbsoluteRegression(n,m,X,Y):\n",
    "\n",
    "    model = AbstractModel()\n",
    "    \n",
    "    # create indexes\n",
    "    model.I = RangeSet(1,n) # observations.\n",
    "    model.J = RangeSet(1,m)  # variables.\n",
    "    \n",
    "    # create variables\n",
    "    model.beta = Var(model.J)  # beta values that we want to get.\n",
    "    model.z = Var(model.I, domain=NonNegativeReals)  # auxiliar variable to manage to linear the objective function.\n",
    "\n",
    "    # create Objective Function\n",
    "    def objective_function(model):\n",
    "        return sum(model.z[i] for i in model.I)\n",
    "    model.OF = Objective(rule=objective_function, sense = minimize)\n",
    "\n",
    "    # create constraints\n",
    "    # (1.1) linear transformation 1.1 constratints\n",
    "    def linear_transformation_11_constraint_rule(model,i):\n",
    "         return -model.z[i] <= Y[i-1][0]-sum(X[i-1,j-1]*model.beta[j] for j in model.J)\n",
    "    model.linear_transformation_11_constraint = Constraint(model.I, rule = linear_transformation_11_constraint_rule)\n",
    "    \n",
    "    # (1.2) linear transformation 1.2 constratints\n",
    "    def linear_transformation_12_constraint_rule(model,i):\n",
    "         return Y[i-1][0]-sum(X[i-1,j-1]*model.beta[j] for j in model.J) <= model.z[i]\n",
    "    model.linear_transformation_12_constraint = Constraint(model.I, rule = linear_transformation_12_constraint_rule)\n",
    "\n",
    "    instance = model.create_instance()\n",
    "    instance.dual = Suffix(direction=Suffix.IMPORT)\n",
    "    results = opt.solve(instance)\n",
    "\n",
    "    x_sol = np.zeros((m))\n",
    "    \n",
    "    for j in range(0,m):\n",
    "        x_sol[j]=instance.beta[j+1].value\n",
    "        \n",
    "    return instance.OF(), x_sol\n",
    "\n",
    "[OF, x_sol]=LeastAbsoluteRegression(n,m,X_real,Y_real)\n",
    "[x_sol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
